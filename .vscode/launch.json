{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "python",
            "request": "launch",
            "program": "/home/qyhuang/miniconda3/envs/dschat/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "/home/qyhuang/LLaMA-Factory",
            "env":{"CUDA_VISIBLE_DEVICES":"7"},
            "args": [
                "--num_gpus=1",
                "--master_port=29500",
                "/home/qyhuang/LLaMA-Factory/src/train.py",
                "--model_name_or_path",
                "/data0/pretrained-models/Qwen2-7B-Instruct",
                "--do_train",
                "--dataset",
                "small_data",
                "--deepspeed",
                "train_bash/deepspeed2.json",
                "--cutoff_len",
                "8192",
                "--template",
                "qwen",
                "--stage",
                "sft",
                "--finetuning_type",
                "full",
                "--output_dir",
                "/data0/sft_output/qwen2-instruct",
                "--overwrite_cache",
                "--cache_dir",
                "/data0/sft_output/cache_dir",
                "--overwrite_output_dir",
                "--per_device_train_batch_size",
                "1",
                "--gradient_accumulation_steps",
                "2",
                "--preprocessing_num_workers",
                "16",
                "--val_size",
                "0.05",
                "--lr_scheduler_type",
                "cosine_with_restarts",
                "--logging_steps",
                "1",
                "--save_steps",
                "5",
                "--learning_rate",
                "5e-5",
                "--num_train_epochs",
                "3",
                "--plot_loss",
                "--report_to",
                "none"
            ]
        }
    ]
}